{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "# Importando os pacotes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from hpsklearn import HyperoptEstimator, knn, random_forest, svc_sigmoid, sgd, gaussian_nb\n",
    "from hyperopt import tpe\n",
    "\n",
    "import functions as f\n",
    "from DataProcesser import DataProcesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o dataset de treinamento\n",
    "dataset = pd.read_csv('../datasets/treino.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x = dataset.drop(['id', 'classe'], axis=1)\n",
    "dataset_y = dataset['classe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_dataset = DataProcesser(X=dataset_x, y=dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processado = dp_dataset.process_train_data(with_target_column=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   num_gestacoes  glicose  pressao_sanguinea  grossura_pele    insulina   bmi  \\\n",
       "0           6.00    148.0               72.0      35.000000  207.514563  33.6   \n",
       "1           1.00     85.0               66.0      29.000000  126.649038  26.6   \n",
       "2           8.00    183.0               64.0      33.014286  207.514563  23.3   \n",
       "3           1.00     89.0               66.0      23.000000   94.000000  28.1   \n",
       "4           5.68    137.0               40.0      35.000000  168.000000  43.1   \n",
       "\n",
       "   indice_historico  idade  num_gestacoes_miss  glicose_miss  \\\n",
       "0             0.627     50                   0             0   \n",
       "1             0.351     31                   0             0   \n",
       "2             0.672     32                   0             0   \n",
       "3             0.167     21                   0             0   \n",
       "4             2.288     33                   1             0   \n",
       "\n",
       "   pressao_sanguinea_miss  grossura_pele_miss  insulina_miss  bmi_miss  \\\n",
       "0                       0                   0              1         0   \n",
       "1                       0                   0              1         0   \n",
       "2                       0                   1              1         0   \n",
       "3                       0                   0              0         0   \n",
       "4                       0                   0              0         0   \n",
       "\n",
       "   indice_historico_miss  idade_miss  missing_total  \n",
       "0                      0           0              1  \n",
       "1                      0           0              1  \n",
       "2                      0           0              2  \n",
       "3                      0           0              0  \n",
       "4                      0           0              1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_gestacoes</th>\n      <th>glicose</th>\n      <th>pressao_sanguinea</th>\n      <th>grossura_pele</th>\n      <th>insulina</th>\n      <th>bmi</th>\n      <th>indice_historico</th>\n      <th>idade</th>\n      <th>num_gestacoes_miss</th>\n      <th>glicose_miss</th>\n      <th>pressao_sanguinea_miss</th>\n      <th>grossura_pele_miss</th>\n      <th>insulina_miss</th>\n      <th>bmi_miss</th>\n      <th>indice_historico_miss</th>\n      <th>idade_miss</th>\n      <th>missing_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.00</td>\n      <td>148.0</td>\n      <td>72.0</td>\n      <td>35.000000</td>\n      <td>207.514563</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.00</td>\n      <td>85.0</td>\n      <td>66.0</td>\n      <td>29.000000</td>\n      <td>126.649038</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.00</td>\n      <td>183.0</td>\n      <td>64.0</td>\n      <td>33.014286</td>\n      <td>207.514563</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.00</td>\n      <td>89.0</td>\n      <td>66.0</td>\n      <td>23.000000</td>\n      <td>94.000000</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.68</td>\n      <td>137.0</td>\n      <td>40.0</td>\n      <td>35.000000</td>\n      <td>168.000000</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "dataset_processado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_validacao, y_treino, y_validacao = train_test_split(dataset_x, dataset_y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_treino = DataProcesser(X=x_treino, y=y_treino)\n",
    "mean_dict = dp_treino.get_means_by_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_validacao = DataProcesser(X=x_validacao, mean_dict=mean_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino_processado = dp_treino.process_train_data(with_target_column=False)\n",
    "x_validacao_processado = dp_validacao.process_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_evals = 10\n",
    "trial_timeout = 300\n",
    "\n",
    "random_forest_estimator = HyperoptEstimator(classifier=random_forest('rf'),\n",
    "                                            algo=tpe.suggest,\n",
    "                                            preprocessing=[],\n",
    "                                            max_evals=n_evals,\n",
    "                                            trial_timeout=trial_timeout)\n",
    "\n",
    "knn_estimator = HyperoptEstimator(classifier=knn('knn'),\n",
    "                                  algo=tpe.suggest,\n",
    "                                  preprocessing=[],\n",
    "                                  max_evals=n_evals,\n",
    "                                  trial_timeout=trial_timeout)\n",
    "\n",
    "svc_estimator = HyperoptEstimator(classifier=svc_sigmoid('svc'),\n",
    "                                  algo=tpe.suggest,\n",
    "                                  preprocessing=[],\n",
    "                                  max_evals=n_evals,\n",
    "                                  trial_timeout=trial_timeout)\n",
    "\n",
    "sgd_estimator = HyperoptEstimator(classifier=sgd('sgd'),\n",
    "                                  algo=tpe.suggest,\n",
    "                                  preprocessing=[],\n",
    "                                  max_evals=n_evals,\n",
    "                                  trial_timeout=trial_timeout)  \n",
    "\n",
    "gaussian_nb_estimator = HyperoptEstimator(classifier=gaussian_nb('gnb'),\n",
    "                                          algo=tpe.suggest,\n",
    "                                          preprocessing=[],\n",
    "                                          max_evals=n_evals,\n",
    "                                          trial_timeout=trial_timeout)                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_list = [random_forest_estimator, knn_estimator, svc_estimator, sgd_estimator, gaussian_nb_estimator]\n",
    "names = ['rf', 'knn', 'svc', 'sgd', 'gnb']\n",
    "\n",
    "models_dict = {}\n",
    "score_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "searching RF best parameters...\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.68s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 3/3 [00:06<00:00,  6.89s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.28s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.90s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.70s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.60s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 8/8 [00:04<00:00,  4.62s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.72s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.79s/trial, best loss: 0.11111111111111116]\n",
      "\n",
      "searching KNN best parameters...\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.51s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.53s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.51s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.47s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.64s/trial, best loss: 0.1444444444444445]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.51s/trial, best loss: 0.1444444444444445]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.48s/trial, best loss: 0.1444444444444445]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.52s/trial, best loss: 0.1444444444444445]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.55s/trial, best loss: 0.1444444444444445]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.52s/trial, best loss: 0.1444444444444445]\n",
      "\n",
      "searching SVC best parameters...\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.51s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.48s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.47s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.47s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.49s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.54s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.57s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.47s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.57s/trial, best loss: 0.4555555555555556]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.52s/trial, best loss: 0.4555555555555556]\n",
      "\n",
      "searching SGD best parameters...\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/trial, best loss: 0.21111111111111114]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.52s/trial, best loss: 0.21111111111111114]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.46s/trial, best loss: 0.21111111111111114]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.51s/trial, best loss: 0.21111111111111114]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.48s/trial, best loss: 0.21111111111111114]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.57s/trial, best loss: 0.21111111111111114]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.51s/trial, best loss: 0.18888888888888888]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.48s/trial, best loss: 0.18888888888888888]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.49s/trial, best loss: 0.18888888888888888]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.55s/trial, best loss: 0.18888888888888888]\n",
      "\n",
      "searching GNB best parameters...\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.56s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.52s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.50s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.46s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.50s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.53s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.44s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.47s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.50s/trial, best loss: 0.2666666666666667]\n"
     ]
    }
   ],
   "source": [
    "for estimator, name in zip(estimators_list, names):\n",
    "    print(f'\\nsearching {name.upper()} best parameters...')\n",
    "\n",
    "    estimator.fit(x_treino_processado, y_treino)\n",
    "    estimator.retrain_best_model_on_full_data(x_treino_processado, y_treino)\n",
    "\n",
    "    best_model = estimator.best_model()['learner']\n",
    "\n",
    "    models_dict[name] = best_model\n",
    "    score_dict[name] = estimator.score(x_validacao_processado, y_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_of_all = models_dict[max(score_dict, key=score_dict.get)]\n",
    "standard_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'rf': 0.7, 'knn': 0.6266666666666667, 'svc': 0.66, 'sgd': 0.64, 'gnb': 0.78}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_model_eval = np.mean(cross_val_score(estimator=best_model_of_all,\n",
    "                                              X=dataset_processado,\n",
    "                                              y=dataset_y,\n",
    "                                              scoring='accuracy',\n",
    "                                              cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_model_eval = np.mean(cross_val_score(estimator=standard_rf,\n",
    "                                              X=dataset_processado,\n",
    "                                              y=dataset_y,\n",
    "                                              scoring='accuracy',\n",
    "                                              cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hyperopt model scored: 0.72\nstandard model scored: 0.89\n\nTraining standard model...\n"
     ]
    }
   ],
   "source": [
    "print(f'hyperopt model scored: {hyperopt_model_eval:0.2f}')\n",
    "print(f'standard model scored: {standard_model_eval:0.2f}')\n",
    "\n",
    "if hyperopt_model_eval > standard_model_eval:\n",
    "    print(f'\\nTraining hyperopt model...')\n",
    "    final_model = best_model_of_all.fit(dataset_processado, dataset_y)\n",
    "else:\n",
    "    print(f'\\nTraining standard model...')\n",
    "    final_model = standard_rf.fit(dataset_processado, dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_dataframe = pd.DataFrame()\n",
    "stacked_dataframe_val = pd.DataFrame()\n",
    "\n",
    "for model in models_dict.values():\n",
    "\n",
    "    try:\n",
    "        model.fit(x_treino_processado, y_treino)\n",
    "\n",
    "        predictions_df = pd.DataFrame(model.predict_proba(x_treino_processado))\n",
    "        predictions_df_val = pd.DataFrame(model.predict_proba(x_validacao_processado))\n",
    "\n",
    "    except Exception:\n",
    "        model.fit(x_treino_processado, y_treino)\n",
    "\n",
    "        predictions_df = pd.DataFrame(model.predict(x_treino_processado), columns=[1])\n",
    "        predictions_df_val = pd.DataFrame(model.predict(x_validacao_processado), columns=[1])\n",
    "\n",
    "    stacked_dataframe = pd.concat([stacked_dataframe, predictions_df], axis=1)\n",
    "    stacked_dataframe_val = pd.concat([stacked_dataframe_val, predictions_df_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino_stacked = stacked_dataframe.loc[:, 1].copy()\n",
    "x_val_stacked = stacked_dataframe_val.loc[:, 1].copy()\n",
    "\n",
    "x_treino_stacked.columns = models_dict.keys()\n",
    "x_val_stacked.columns = models_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "np.mean(cross_val_score(estimator=standard_rf,\n",
    "                        X=x_treino_stacked,\n",
    "                        y=y_treino,\n",
    "                        scoring='accuracy',\n",
    "                        cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_rf2 = RandomForestClassifier()\r\n",
    "stacked_model = standard_rf2.fit(x_treino_stacked, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(stacked_model.predict(x_val_stacked), y_validacao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_model(final_model, 'models', 'ia_doctor')\n",
    "f.save_model(mean_dict, 'imputers', 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "models/ia_doctor_v2.h5\nimputers/mean_v2.h5\n"
     ]
    }
   ],
   "source": [
    "loaded_model = f.load_last_model('models')\n",
    "imputer = f.load_last_model('imputers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_teste = pd.read_csv('../datasets/teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      0     1\n",
       "0  0.68  0.32\n",
       "1  0.65  0.35\n",
       "2  0.61  0.39\n",
       "3  0.73  0.27\n",
       "4  0.55  0.45\n",
       "5  0.54  0.46\n",
       "6  0.44  0.56\n",
       "7  0.99  0.01\n",
       "8  0.64  0.36\n",
       "9  0.92  0.08"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.68</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.65</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.61</td>\n      <td>0.39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.73</td>\n      <td>0.27</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.55</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.54</td>\n      <td>0.46</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.44</td>\n      <td>0.56</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.99</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.64</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.92</td>\n      <td>0.08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "predictions_proba = f.process_and_predict_proba(dataset=dataset_teste, model=loaded_model, imputer=imputer, drop_cols='id')\n",
    "pd.DataFrame(predictions_proba).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = f.process_and_predict(dataset=dataset_teste, model=loaded_model, imputer=imputer, drop_cols='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_teste['classe'] = predictions\n",
    "resposta = dataset_teste.loc[:, ['id', 'classe']]\n",
    "resposta.to_csv('../datasets/best_answer.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}